1. Android build, support cross-compilation (currently supported via CMake)

2. Mac M1 optimization for NNUE. Produce a signed M1 executable for Mac.

3. FRC

4. implement UCI_Opponent

5. change reduction/pruning based on node type - does not work so far.

6. New book format? (LMBD - https://en.wikipedia.org/wiki/Lightning_Memory-Mapped_Database. Or LevelDB, RocksDB).

7. Book learning. Dropout expansion? Implement aa sytem for learning from self-play games.

8. Eval tuner ideas:
    a.  Allow tuner to use mini-batches.
    b.  Look into SVRG for optimization (https://papers.nips.cc/paper/4937-accelerating-stochastic-gradient-descent-using-predictive-variance-reduction.pdf).
    c.  Experiment with regulatization (currently not used).
    d.  Consider L1 regularization for tuner, possibly with smooth approximation (http://pages.cs.wisc.edu/~gfung/GeneralL1/L1_approx_bounds.pdf)
    e.  Properly implement ordinal logistic regression in tuner. Consider using all-threshold as in Rennie paper (http://ttic.uchicago.edu/~nati/Publications/RennieSrebroIJCAI05.pdf).

9. Arasan seems to use less time than many opponents do, at least in Winboard mode with ponder on. (This has been at least partialy addresed).

10. Further LazySMP improvements:
   a. see http://www.tckerrigan.com/Chess/Parallel_Search/Simplified_ABDADA/
   b. improve thread depth distribution logic, see: http://talkchess.com/forum3/viewtopic.php?f=7&t=68154. - done, needs more testing though.

11. for NUMA: consider memory striping for hash. Rebind memory on thread resize.

12. Windows GUI badly needs a rewrite, better graphics.

13. Make logging work properly under UCI.

14. Implement position learning in UCI mode.


